/**
 * Directus Extension: OpenAI Service
 * Migrado de: backend/app/Services/OpenAIService.php
 * 
 * Endpoints dispon√≠veis:
 * - POST /openai/transcribe - Transcrever √°udio (Whisper)
 * - POST /openai/chat - Chat completion (GPT-4o-mini)
 * - POST /openai/extract - Extrair dados estruturados
 * - POST /openai/diagnostic - Gerar diagn√≥stico de lead
 */

import FormData from 'form-data';
import fetch from 'node-fetch';
import fs from 'fs';

export default (router, { env, logger }) => {
	const OPENAI_API_KEY = env.OPENAI_API_KEY;
	const OPENAI_MODEL = env.OPENAI_MODEL || 'gpt-4o-mini';
	const AI_ASSISTANT_NAME = env.AI_ASSISTANT_NAME || 'Teresa';

	/**
	 * POST /openai/transcribe
	 * Transcrever √°udio usando Whisper API
	 * 
	 * Body: { audioPath: string } ou FormData com file
	 */
	router.post('/transcribe', async (req, res) => {
		try {
			const { audioPath } = req.body;

			if (!audioPath && !req.files?.file) {
				return res.status(400).json({
					success: false,
					error: 'audioPath ou file √© obrigat√≥rio'
				});
			}

			logger.info('üé§ Iniciando transcri√ß√£o Whisper', { audioPath });

			const formData = new FormData();
			
			if (req.files?.file) {
				// Arquivo enviado via multipart
				formData.append('file', req.files.file.data, {
					filename: req.files.file.name,
					contentType: req.files.file.mimetype
				});
			} else {
				// Arquivo no sistema de arquivos
				formData.append('file', fs.createReadStream(audioPath));
			}

			formData.append('model', 'whisper-1');
			formData.append('language', 'pt');

			const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
				method: 'POST',
				headers: {
					'Authorization': `Bearer ${OPENAI_API_KEY}`,
					...formData.getHeaders()
				},
				body: formData
			});

			const data = await response.json();

			if (response.status === 200) {
				logger.info('‚úÖ Transcri√ß√£o bem-sucedida', {
					text: data.text,
					length: data.text.length
				});

				return res.json({
					success: true,
					text: data.text
				});
			}

			logger.error('‚ùå Falha na transcri√ß√£o', {
				status: response.status,
				data
			});

			return res.status(response.status).json({
				success: false,
				error: 'Transcription failed',
				details: data
			});

		} catch (error) {
			logger.error('‚ùå Erro ao transcrever √°udio', {
				error: error.message,
				stack: error.stack
			});

			return res.status(500).json({
				success: false,
				error: error.message
			});
		}
	});

	/**
	 * POST /openai/chat
	 * Chat completion com GPT
	 * 
	 * Body: {
	 *   systemPrompt: string,
	 *   userPrompt: string,
	 *   temperature?: number,
	 *   maxTokens?: number
	 * }
	 */
	router.post('/chat', async (req, res) => {
		try {
			const {
				systemPrompt,
				userPrompt,
				temperature = 0.7,
				maxTokens = 500
			} = req.body;

			if (!systemPrompt || !userPrompt) {
				return res.status(400).json({
					success: false,
					error: 'systemPrompt e userPrompt s√£o obrigat√≥rios'
				});
			}

			logger.info('ü§ñ Chat completion solicitado', {
				systemPromptLength: systemPrompt.length,
				userPromptLength: userPrompt.length
			});

			const response = await fetch('https://api.openai.com/v1/chat/completions', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Authorization': `Bearer ${OPENAI_API_KEY}`
				},
				body: JSON.stringify({
					model: OPENAI_MODEL,
					messages: [
						{ role: 'system', content: systemPrompt },
						{ role: 'user', content: userPrompt }
					],
					temperature,
					max_tokens: maxTokens
				})
			});

			const data = await response.json();

			if (response.status === 200) {
				const content = data.choices[0]?.message?.content || '';

				logger.info('‚úÖ Chat completion bem-sucedido', {
					contentLength: content.length
				});

				return res.json({
					success: true,
					content: content.trim()
				});
			}

			logger.error('‚ùå Falha no chat completion', {
				status: response.status,
				data
			});

			return res.status(response.status).json({
				success: false,
				error: 'Chat completion failed',
				details: data
			});

		} catch (error) {
			logger.error('‚ùå Erro no chat completion', {
				error: error.message,
				stack: error.stack
			});

			return res.status(500).json({
				success: false,
				error: error.message
			});
		}
	});

	/**
	 * POST /openai/extract
	 * Extrair dados estruturados do lead
	 * 
	 * Body: { conversationHistory: string }
	 */
	router.post('/extract', async (req, res) => {
		try {
			const { conversationHistory } = req.body;

			if (!conversationHistory) {
				return res.status(400).json({
					success: false,
					error: 'conversationHistory √© obrigat√≥rio'
				});
			}

			logger.info('üìä Extra√ß√£o de dados solicitada');

			const systemPrompt = `Voc√™ √© um analista que l√™ conversas de atendimento imobili√°rio e transforma tudo em dados estruturados.

‚ö†Ô∏è FOQUE NAS √öLTIMAS MENSAGENS - elas t√™m PRIORIDADE TOTAL!

Extraia SEMPRE um JSON com as seguintes chaves (use null se n√£o houver dado):
{
  "budget_min": n√∫mero (apenas d√≠gitos, sem formata√ß√£o),
  "budget_max": n√∫mero (apenas d√≠gitos, sem formata√ß√£o),
  "localizacao": string (bairro ou regi√£o mencionada),
  "quartos": n√∫mero inteiro,
  "suites": n√∫mero inteiro,
  "garagem": n√∫mero inteiro,
  "caracteristicas_desejadas": string,
  "cpf": CPF apenas com 11 d√≠gitos (sem pontos ou tra√ßos),
  "renda_mensal": n√∫mero (apenas d√≠gitos, sem formata√ß√£o),
  "estado_civil": string,
  "composicao_familiar": string,
  "profissao": string,
  "fonte_renda": string,
  "financiamento_status": string,
  "prazo_compra": string,
  "objetivo_compra": string,
  "preferencia_tipo_imovel": string,
  "preferencia_bairro": string,
  "preferencia_lazer": string,
  "preferencia_seguranca": string,
  "observacoes_cliente": string
}

‚ö†Ô∏è REGRAS CR√çTICAS:
1. Se houver m√∫ltiplos valores, SEMPRE escolha o MAIS RECENTE (√∫ltima mensagem tem prioridade)
2. Extraia CPF mesmo sem formata√ß√£o (ex: 91963214234)
3. Renda mensal: converta valores como "150000" ou "5 mil" para n√∫mero puro
4. N√ÉO invente informa√ß√µes - retorne null se n√£o tiver certeza
5. Retorne SOMENTE o JSON, sem texto adicional

Exemplos de extra√ß√£o:
- Cliente: "Meu CPF √© 91963214234" ‚Üí {"cpf": "91963214234"}
- Cliente: "150000" ou "minha renda mensal √© de 150000" ‚Üí {"renda_mensal": 150000}
- Cliente: "quero 3 quartos" ‚Üí {"quartos": 3}`;

			const userPrompt = `Conversa:\n\n${conversationHistory}\n\nResponda apenas com o JSON solicitado. FOQUE NAS √öLTIMAS MENSAGENS!`;

			const chatResponse = await fetch('https://api.openai.com/v1/chat/completions', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Authorization': `Bearer ${OPENAI_API_KEY}`
				},
				body: JSON.stringify({
					model: OPENAI_MODEL,
					messages: [
						{ role: 'system', content: systemPrompt },
						{ role: 'user', content: userPrompt }
					],
					temperature: 0.7,
					max_tokens: 500
				})
			});

			const chatData = await chatResponse.json();

			if (chatResponse.status === 200) {
				const content = chatData.choices[0]?.message?.content || '';

				try {
					const extracted = JSON.parse(content);

					logger.info('‚úÖ Dados extra√≠dos com sucesso', {
						fieldsExtracted: Object.keys(extracted).filter(k => extracted[k] !== null)
					});

					return res.json({
						success: true,
						data: extracted
					});
				} catch (parseError) {
					logger.error('‚ùå Falha ao parsear JSON da resposta', {
						content
					});

					return res.status(422).json({
						success: false,
						error: 'Failed to parse JSON response',
						rawContent: content
					});
				}
			}

			logger.error('‚ùå Falha na extra√ß√£o de dados', {
				status: chatResponse.status,
				data: chatData
			});

			return res.status(chatResponse.status).json({
				success: false,
				error: 'Data extraction failed',
				details: chatData
			});

		} catch (error) {
			logger.error('‚ùå Erro ao extrair dados', {
				error: error.message,
				stack: error.stack
			});

			return res.status(500).json({
				success: false,
				error: error.message
			});
		}
	});

	/**
	 * POST /openai/diagnostic
	 * Gerar diagn√≥stico inteligente de lead
	 * 
	 * Body: {
	 *   leadProfile: object,
	 *   conversationHistory: string,
	 *   availableProperties: array
	 * }
	 */
	router.post('/diagnostic', async (req, res) => {
		try {
			const {
				leadProfile,
				conversationHistory,
				availableProperties = []
			} = req.body;

			if (!leadProfile || !conversationHistory) {
				return res.status(400).json({
					success: false,
					error: 'leadProfile e conversationHistory s√£o obrigat√≥rios'
				});
			}

			logger.info('ü©∫ Diagn√≥stico de lead solicitado', {
				leadId: leadProfile.id
			});

			const systemPrompt = `Voc√™ √© um especialista imobili√°rio que prepara diagn√≥sticos para corretores humanos.
Monte um relat√≥rio objetivo com os blocos: 
1. Perfil geral do cliente
2. Capacidade financeira (inclua renda, or√ßamento e viabilidade)
3. Prefer√™ncias e gatilhos emocionais
4. Riscos e pontos de aten√ß√£o
5. Sugest√µes de abordagem para o corretor.

Use apenas informa√ß√µes confirmadas. Se faltar algum dado relevante, sinalize como 'Pendentes'.`;

			const profileJson = JSON.stringify(leadProfile, null, 2);
			const propertiesJson = JSON.stringify(availableProperties, null, 2);

			const userPrompt = `DADOS DO LEAD:\n${profileJson}\n\nHIST√ìRICO DA CONVERSA:\n${conversationHistory}\n\nIM√ìVEIS INDICADOS:\n${propertiesJson}\n\nGere o diagn√≥stico conforme solicitado.`;

			const chatResponse = await fetch('https://api.openai.com/v1/chat/completions', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Authorization': `Bearer ${OPENAI_API_KEY}`
				},
				body: JSON.stringify({
					model: OPENAI_MODEL,
					messages: [
						{ role: 'system', content: systemPrompt },
						{ role: 'user', content: userPrompt }
					],
					temperature: 0.7,
					max_tokens: 500
				})
			});

			const chatData = await chatResponse.json();

			if (chatResponse.status === 200) {
				const content = chatData.choices[0]?.message?.content || '';

				logger.info('‚úÖ Diagn√≥stico gerado com sucesso', {
					contentLength: content.length
				});

				return res.json({
					success: true,
					content: content.trim()
				});
			}

			logger.error('‚ùå Falha ao gerar diagn√≥stico', {
				status: chatResponse.status,
				data: chatData
			});

			return res.status(chatResponse.status).json({
				success: false,
				error: 'Diagnostic generation failed',
				details: chatData
			});

		} catch (error) {
			logger.error('‚ùå Erro ao gerar diagn√≥stico', {
				error: error.message,
				stack: error.stack
			});

			return res.status(500).json({
				success: false,
				error: error.message
			});
		}
	});

	/**
	 * POST /openai/process-message
	 * Processar mensagem e gerar resposta contextual
	 * 
	 * Body: {
	 *   message: string,
	 *   context?: string,
	 *   isFromAudio?: boolean,
	 *   availableProperties?: array,
	 *   leadData?: object
	 * }
	 */
	router.post('/process-message', async (req, res) => {
		try {
			const {
				message,
				context = '',
				isFromAudio = false,
				availableProperties = [],
				leadData = null
			} = req.body;

			if (!message) {
				return res.status(400).json({
					success: false,
					error: 'message √© obrigat√≥rio'
				});
			}

			logger.info('üí¨ Processando mensagem', {
				messageLength: message.length,
				isFromAudio,
				hasProperties: availableProperties.length > 0,
				hasLeadData: !!leadData
			});

			const audioInstruction = isFromAudio
				? "\n- O cliente acabou de enviar um √ÅUDIO que foi transcrito. Responda de forma natural, mostrando que voc√™ OUVIU e ENTENDEU o que ele disse. Use express√µes como 'Entendi!', 'Certo!', 'Perfeito!' para confirmar que voc√™ ouviu."
				: "";

			// Verificar dados faltantes do lead
			let dataCollectionContext = '';
			const dadosFaltantes = [];

			if (leadData) {
				// Prioridade 1: Dados cadastrais b√°sicos
				if (!leadData.nome) dadosFaltantes.push('nome');
				if (!leadData.telefone) dadosFaltantes.push('telefone');
				if (!leadData.cpf) dadosFaltantes.push('CPF');
				if (!leadData.email) dadosFaltantes.push('email');

				// Prioridade 2: Dados financeiros
				if (!leadData.renda_mensal) dadosFaltantes.push('renda mensal');
				if (!leadData.budget_min) dadosFaltantes.push('or√ßamento m√≠nimo');
				if (!leadData.budget_max) dadosFaltantes.push('or√ßamento m√°ximo');

				// Prioridade 3: Dados pessoais
				if (!leadData.estado_civil) dadosFaltantes.push('estado civil');
				if (!leadData.composicao_familiar) dadosFaltantes.push('composi√ß√£o familiar');
				if (!leadData.profissao) dadosFaltantes.push('profiss√£o');
				if (!leadData.fonte_renda) dadosFaltantes.push('fonte de renda');

				// Prioridade 4: Prefer√™ncias de im√≥vel
				if (!leadData.localizacao) dadosFaltantes.push('localiza√ß√£o desejada');
				if (!leadData.quartos) dadosFaltantes.push('quantidade de quartos');
				if (!leadData.objetivo_compra) dadosFaltantes.push('objetivo da compra');

				if (dadosFaltantes.length > 0) {
					dataCollectionContext = `\n\n‚ö†Ô∏è DADOS FALTANTES DO LEAD (pergunte de forma SUTIL):\n- ${dadosFaltantes.join('\n- ')}\n`;
					dataCollectionContext += `\nüí° Estrat√©gia: Termine SEMPRE perguntando por UM dado faltante (escolha o mais importante).\n`;
				}
			}

			// Contexto de im√≥veis dispon√≠veis
			let propertiesContext = '';
			if (availableProperties.length > 0) {
				propertiesContext = "\n\n=== IM√ìVEIS DISPON√çVEIS NO BANCO DE DADOS (DADOS REAIS) ===\n";
				
				availableProperties.forEach(prop => {
					const totalQuartos = (prop.dormitorios || 0) + (prop.suites || 0);
					
					let imagens = prop.imagens;
					if (typeof imagens === 'string') {
						try {
							imagens = JSON.parse(imagens);
						} catch {
							imagens = null;
						}
					}

					let imageLinks = '';
					if (Array.isArray(imagens) && imagens.length > 0) {
						const validImages = imagens
							.map(img => typeof img === 'string' ? img : img?.url)
							.filter(Boolean)
							.slice(0, 5);
						
						if (validImages.length > 0) {
							imageLinks = validImages.join('\n  ');
						}
					}

					propertiesContext += `
üìç ${prop.codigo_imovel || 'S/N'} - ${prop.tipo_imovel || 'Im√≥vel'}
   Localiza√ß√£o: ${prop.bairro || 'N/A'}, ${prop.cidade || 'N/A'}
   Valor: R$ ${prop.valor_venda ? prop.valor_venda.toLocaleString('pt-BR') : 'N/A'}
   Quartos: ${totalQuartos} (${prop.dormitorios || 0} dormit√≥rios + ${prop.suites || 0} su√≠tes)
   Descri√ß√£o: ${prop.descricao || 'N/A'}${imageLinks ? `\n   Fotos:\n  ${imageLinks}` : ''}
`;
				});

				propertiesContext += "‚ö†Ô∏è IMPORTANTE: Quando o cliente pedir 'X quartos', considere o TOTAL (dormit√≥rios + su√≠tes)!\n";
				propertiesContext += "‚ö†Ô∏è FOTOS: Quando o cliente pedir fotos de um im√≥vel, ENVIE os links diretamente se dispon√≠veis acima!\n";
			}

			const systemPrompt = `Voc√™ √© ${AI_ASSISTANT_NAME}, atendente virtual da Exclusiva Lar Im√≥veis, uma imobili√°ria especializada.

Seu objetivo √©:
- Se apresentar como ${AI_ASSISTANT_NAME} e confirmar como o cliente prefere ser chamado
- Ser cordial, profissional mas CASUAL e leve na conversa
- **COLETAR DADOS IMPORTANTES de forma PERSISTENTE mas GENTIL**
- SEMPRE terminar sua resposta perguntando por UM dado faltante (veja contexto abaixo)
- Quando o cliente fornecer CPF ou renda, AGRADE√áA e confirme que registrou
- N√£o fazer muitas perguntas de uma vez - 1 pergunta de dados por resposta
- Quando receber documentos, avisar que um corretor validar√°
- Manter tom conversacional e amig√°vel${audioInstruction}
${propertiesContext}
${dataCollectionContext}

REGRAS CR√çTICAS:
- Respostas curtas e diretas (m√°ximo 3 linhas)
- ‚ö†Ô∏è SEMPRE termine com uma pergunta sobre um dado faltante (CPF, renda, or√ßamento, localiza√ß√£o ou quartos)
- ‚ö†Ô∏è Seja SUTIL: n√£o diga "preciso" ou "√© obrigat√≥rio", diga "pra te ajudar melhor" ou "s√≥ pra agilizar"
- ‚ö†Ô∏è NUNCA diga que n√£o temos um im√≥vel sem CONSULTAR a lista acima
- ‚ö†Ô∏è Quando o cliente pedir X quartos, considere TOTAL (dormit√≥rios + su√≠tes)`;

			const userPrompt = (context ? `Contexto anterior:\n${context}\n\n` : "") + `Cliente: ${message}\n\nResponda:`;

			const chatResponse = await fetch('https://api.openai.com/v1/chat/completions', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Authorization': `Bearer ${OPENAI_API_KEY}`
				},
				body: JSON.stringify({
					model: OPENAI_MODEL,
					messages: [
						{ role: 'system', content: systemPrompt },
						{ role: 'user', content: userPrompt }
					],
					temperature: 0.7,
					max_tokens: 500
				})
			});

			const chatData = await chatResponse.json();

			if (chatResponse.status === 200) {
				const content = chatData.choices[0]?.message?.content || '';

				logger.info('‚úÖ Mensagem processada com sucesso', {
					responseLength: content.length
				});

				return res.json({
					success: true,
					content: content.trim()
				});
			}

			logger.error('‚ùå Falha ao processar mensagem', {
				status: chatResponse.status,
				data: chatData
			});

			return res.status(chatResponse.status).json({
				success: false,
				error: 'Message processing failed',
				details: chatData
			});

		} catch (error) {
			logger.error('‚ùå Erro ao processar mensagem', {
				error: error.message,
				stack: error.stack
			});

			return res.status(500).json({
				success: false,
				error: error.message
			});
		}
	});
};
